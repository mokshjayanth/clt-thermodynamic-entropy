{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Molecular Configurations\n",
    "\n",
    "## Understanding Thermodynamic Entropy Through the Central Limit Theorem\n",
    "\n",
    "**Interactive Demonstration**: This notebook explores how the Central Limit Theorem explains the emergence of thermodynamic behavior in macroscopic systems.\n",
    "\n",
    "### Overview\n",
    "\n",
    "We model N ink molecules diffusing in water, where each molecule has a 50% probability of being in the left or right half of the container. This simple binomial system demonstrates how microscopic randomness leads to deterministic macroscopic behavior, with relative fluctuations scaling as **1/‚àöN**.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- For small N: Distribution is noticeably spread out\n",
    "- For large N: Distribution becomes extremely narrow relative to the mean\n",
    "- For N ‚âà 10¬≤¬≥ (macroscopic): Relative width ~ 10‚Åª¬π¬≤ ‚Üí essentially deterministic\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (Uncomment the next line and run this cell if packages are missing)\n",
    "# %pip install numpy scipy plotly ipywidgets nbformat==4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.special import gammaln, comb\n",
    "from scipy.stats import binom, norm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì All packages loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "from IPython.display import display\n",
    "\n",
    "# Set plotly renderer\n",
    "try:\n",
    "    import google.colab  # Only exists in Colab\n",
    "    pio.renderers.default = \"colab\"\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "except ImportError:\n",
    "    pio.renderers.default = \"notebook\"  # Or \"inline\" or your preferred default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mathematical Functions\n",
    "\n",
    "### Core Probability Distributions\n",
    "\n",
    "We implement both exact binomial and normal approximations:\n",
    "\n",
    "**Exact Binomial PMF:**\n",
    "$$P(k) = \\binom{N}{k} \\cdot p^k \\cdot (1-p)^{N-k} = \\binom{N}{k} \\cdot \\left(\\frac{1}{2}\\right)^N$$\n",
    "\n",
    "**Normal Approximation (CLT):**\n",
    "$$f(k) \\approx \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(k-\\mu)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "where $\\mu = N/2$ and $\\sigma = \\sqrt{N/4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_factorial(x):\n",
    "    \"\"\"\n",
    "    Compute log(x!) using Stirling's approximation for large x.\n",
    "    For small x, compute exact value.\n",
    "    \"\"\"\n",
    "    if x <= 1:\n",
    "        return 0\n",
    "    if x < 20:\n",
    "        # Exact for small values\n",
    "        return np.sum(np.log(np.arange(2, x + 1)))\n",
    "    # Stirling's approximation\n",
    "    return x * np.log(x) - x + 0.5 * np.log(2 * np.pi * x)\n",
    "\n",
    "def log_binomial(n, k):\n",
    "    \"\"\"\n",
    "    Compute log(C(n,k)) to avoid overflow.\n",
    "    \"\"\"\n",
    "    if k > n or k < 0:\n",
    "        return -np.inf\n",
    "    if k == 0 or k == n:\n",
    "        return 0\n",
    "    return log_factorial(n) - log_factorial(k) - log_factorial(n - k)\n",
    "\n",
    "def exact_binomial_pmf(k, n, p=0.5):\n",
    "    \"\"\"\n",
    "    Compute EXACT binomial PMF using logarithmic methods.\n",
    "    P(k) = C(n,k) * p^k * (1-p)^(n-k)\n",
    "    \"\"\"\n",
    "    log_prob = log_binomial(n, k) + k * np.log(p) + (n - k) * np.log(1 - p)\n",
    "    return np.exp(log_prob)\n",
    "\n",
    "def normal_pdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Normal probability density function.\n",
    "    \"\"\"\n",
    "    coefficient = 1 / (sigma * np.sqrt(2 * np.pi))\n",
    "    exponent = -np.power(x - mu, 2) / (2 * np.power(sigma, 2))\n",
    "    return coefficient * np.exp(exponent)\n",
    "\n",
    "def compute_entropy(p, N):\n",
    "    \"\"\"\n",
    "    Compute normalized entropy using KL divergence.\n",
    "    S = -N * [p*log2(p) + (1-p)*log2(1-p)]\n",
    "    Returns: S/N (normalized entropy)\n",
    "    \"\"\"\n",
    "    if p <= 0 or p >= 1:\n",
    "        return 0\n",
    "    entropy = -N * (p * np.log2(p) + (1 - p) * np.log2(1 - p))\n",
    "    return entropy / N\n",
    "\n",
    "print(\"‚úì Mathematical functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distribution_data(log_N, visual_mode='smooth'):\n",
    "    \"\"\"\n",
    "    Generate distribution data based on N and visualization mode.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    log_N : int\n",
    "        Logarithm base 10 of number of molecules\n",
    "    visual_mode : str\n",
    "        'smooth', 'discrete', or 'both'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with distribution data and statistics\n",
    "    \"\"\"\n",
    "    N = int(10**log_N)\n",
    "    mean = N / 2\n",
    "    sd = np.sqrt(N / 4)\n",
    "    \n",
    "    # Thresholds for computation methods\n",
    "    use_exact_binomial = N <= 1_000_000\n",
    "    use_discrete = N <= 100_000\n",
    "    \n",
    "    k_values = []\n",
    "    fractions = []\n",
    "    probabilities = []\n",
    "    entropies = []\n",
    "    \n",
    "    if use_discrete and visual_mode in ['discrete', 'both']:\n",
    "        # Discrete sampling: integer k values\n",
    "        start = max(0, int(np.ceil(mean - 6 * sd)))\n",
    "        end = min(N, int(np.floor(mean + 6 * sd)))\n",
    "        \n",
    "        for k in range(start, end + 1):\n",
    "            fraction = (k / N) * 100\n",
    "            \n",
    "            # Use exact binomial if N is small enough\n",
    "            if use_exact_binomial:\n",
    "                prob = exact_binomial_pmf(k, N)\n",
    "            else:\n",
    "                prob = normal_pdf(k, mean, sd)\n",
    "            \n",
    "            # Entropy\n",
    "            p = k / N\n",
    "            entropy = compute_entropy(p, N)\n",
    "            \n",
    "            k_values.append(k)\n",
    "            fractions.append(fraction)\n",
    "            probabilities.append(prob)\n",
    "            entropies.append(entropy)\n",
    "    else:\n",
    "        # Continuous sampling for smooth curves\n",
    "        num_points = 300\n",
    "        start = max(0, mean - 6 * sd)\n",
    "        end = min(N, mean + 6 * sd)\n",
    "        k_continuous = np.linspace(start, end, num_points)\n",
    "        \n",
    "        for k in k_continuous:\n",
    "            fraction = (k / N) * 100\n",
    "            prob = normal_pdf(k, mean, sd)\n",
    "            \n",
    "            # Entropy\n",
    "            p = k / N\n",
    "            entropy = compute_entropy(p, N)\n",
    "            \n",
    "            k_values.append(k)\n",
    "            fractions.append(fraction)\n",
    "            probabilities.append(prob)\n",
    "            entropies.append(entropy)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    relative_sd = (sd / mean * 100)\n",
    "    sigma_range_1 = [(mean - sd) / N * 100, (mean + sd) / N * 100]\n",
    "    sigma_range_3 = [(mean - 3*sd) / N * 100, (mean + 3*sd) / N * 100]\n",
    "    \n",
    "    return {\n",
    "        'N': N,\n",
    "        'mean': mean,\n",
    "        'sd': sd,\n",
    "        'k_values': k_values,\n",
    "        'log_N': log_N, # Add log_N to the data dictionary\n",
    "        'fractions': fractions,\n",
    "        'probabilities': probabilities,\n",
    "        'entropies': entropies,\n",
    "        'relative_sd': relative_sd,\n",
    "        'sigma_range_1': sigma_range_1,\n",
    "        'sigma_range_3': sigma_range_3,\n",
    "        'is_discrete': use_discrete and visual_mode in ['discrete', 'both'],\n",
    "        'is_exact': use_exact_binomial and use_discrete and visual_mode in ['discrete', 'both']\n",
    "    }\n",
    "\n",
    "print(\"‚úì Data generation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distribution_plot(data, visual_mode='smooth'):\n",
    "    \"\"\"\n",
    "    Create an interactive plotly visualization of the distribution.\n",
    "    \"\"\"\n",
    "    # Determine if we need a second y-axis for entropy\n",
    "    show_entropy = visual_mode == 'both'\n",
    "    \n",
    "    if show_entropy:\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    else:\n",
    "        fig = go.Figure()\n",
    "    \n",
    "    # Main probability plot\n",
    "    if data['is_discrete'] and visual_mode == 'discrete':\n",
    "        # Bar chart for discrete mode\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=data['fractions'],\n",
    "                y=data['probabilities'],\n",
    "                name='Probability (PMF)',\n",
    "                marker_color='rgba(99, 102, 241, 0.6)',\n",
    "                hovertemplate='<b>%{x:.6f}% in left half</b><br>' +\n",
    "                              'Probability: %{y:.4e}<br>' +\n",
    "                              '<extra></extra>'\n",
    "            ),\n",
    "            secondary_y=False if show_entropy else None\n",
    "        )\n",
    "    else:\n",
    "        # Line chart for smooth mode\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data['fractions'],\n",
    "                y=data['probabilities'],\n",
    "                name='Probability Density',\n",
    "                mode='lines',\n",
    "                line=dict(color='rgb(99, 102, 241)', width=3),\n",
    "                hovertemplate='<b>%{x:.6f}% in left half</b><br>' +\n",
    "                'Probability Density: %{y:.4e}<br>' + \n",
    "                '<extra></extra>'\n",
    "            ),\n",
    "            secondary_y=False if show_entropy else None\n",
    "        )\n",
    "    \n",
    "    # Add entropy curve if in 'both' mode\n",
    "    if show_entropy:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data['fractions'],\n",
    "                y=data['entropies'],\n",
    "                name='Relative Entropy',\n",
    "                mode='lines',\n",
    "                line=dict(color='rgb(16, 185, 129)', width=2, dash='dash'),\n",
    "                hovertemplate='<b>%{x:.6f}% in left half</b><br>' +\n",
    "                              'Rel. Entropy: %{y:.6f}<br>' +\n",
    "                              '<extra></extra>'\n",
    "            ),\n",
    "            secondary_y=True\n",
    "        )\n",
    "    \n",
    "    # Add reference line at 50%\n",
    "    fig.add_vline(\n",
    "        x=50,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"red\",\n",
    "        annotation_text=\"Uniform (50%)\",\n",
    "        annotation_position=\"top\"\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    title_text = f\"Probability Distribution for N = 10^{data['log_N']} = {data['N']:.2e} Molecules\"\n",
    "    if data['is_exact']:\n",
    "        title_text += \" <i>(Exact Binomial PMF)</i>\"\n",
    "    elif data['is_discrete']:\n",
    "        title_text += \" <i>(Normal Approximation)</i>\"\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title_text,\n",
    "        xaxis_title=\"Percentage of molecules in left half (%)\",\n",
    "        height=500,\n",
    "        hovermode='closest',\n",
    "        template='plotly_white',\n",
    "        showlegend=True,\n",
    "        legend=dict(x=0.02, y=0.98, bgcolor='rgba(255,255,255,0.8)')\n",
    "    )\n",
    "    \n",
    "    # Update y-axes\n",
    "    if show_entropy:\n",
    "        if data['is_discrete']:\n",
    "            fig.update_yaxes(title_text=\"Probability\", type=\"log\", secondary_y=False)\n",
    "        else:\n",
    "            fig.update_yaxes(title_text=\"Probability Density\", type=\"log\", secondary_y=False)\n",
    "        fig.update_yaxes(title_text=\"Relative Entropy\", range=[0, 1], secondary_y=True)\n",
    "    else:\n",
    "        if data['is_discrete']:\n",
    "            fig.update_yaxes(title_text=\"Probability\", type=\"log\")\n",
    "        else:\n",
    "            fig.update_yaxes(title_text=\"Probability Density\", type=\"log\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"‚úì Visualization function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistics Display Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_statistics(data):\n",
    "    \"\"\"\n",
    "    Display key statistics in a formatted manner.\n",
    "    \"\"\"\n",
    "    stats_html = f\"\"\"\n",
    "    <div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; margin: 20px 0;\">\n",
    "        <div style=\"background: #EFF6FF; padding: 15px; border-radius: 8px; border: 2px solid #BFDBFE;\">\n",
    "            <p style=\"color: #6B7280; font-size: 14px; margin: 0;\">Peak (Most Probable)</p>\n",
    "            <p style=\"color: #2563EB; font-size: 24px; font-weight: bold; margin: 5px 0;\">50.000000%</p>\n",
    "            <p style=\"color: #9CA3AF; font-size: 12px; margin: 0;\">Uniform distribution</p>\n",
    "        </div>\n",
    "        <div style=\"background: #ECFDF5; padding: 15px; border-radius: 8px; border: 2px solid #A7F3D0;\">\n",
    "            <p style=\"color: #6B7280; font-size: 14px; margin: 0;\">Relative Std Dev</p>\n",
    "            <p style=\"color: #10B981; font-size: 20px; font-weight: bold; margin: 5px 0;\">{data['relative_sd']:.8f}%</p>\n",
    "            <p style=\"color: #9CA3AF; font-size: 12px; margin: 0;\">œÉ/Œº = 1/‚àöN</p>\n",
    "        </div>\n",
    "        <div style=\"background: #F5F3FF; padding: 15px; border-radius: 8px; border: 2px solid #DDD6FE;\">\n",
    "            <p style=\"color: #6B7280; font-size: 14px; margin: 0;\">¬±1œÉ Range</p>\n",
    "            <p style=\"color: #8B5CF6; font-size: 16px; font-weight: bold; margin: 5px 0;\">\n",
    "                {data['sigma_range_1'][0]:.6f}%<br/>to {data['sigma_range_1'][1]:.6f}%\n",
    "            </p>\n",
    "            <p style=\"color: #9CA3AF; font-size: 12px; margin: 0;\">68% probability</p>\n",
    "        </div>\n",
    "        <div style=\"background: #FFF7ED; padding: 15px; border-radius: 8px; border: 2px solid #FED7AA;\">\n",
    "            <p style=\"color: #6B7280; font-size: 14px; margin: 0;\">¬±3œÉ Range</p>\n",
    "            <p style=\"color: #F97316; font-size: 16px; font-weight: bold; margin: 5px 0;\">\n",
    "                {data['sigma_range_3'][0]:.8f}%<br/>to {data['sigma_range_3'][1]:.8f}%\n",
    "            </p>\n",
    "            <p style=\"color: #9CA3AF; font-size: 12px; margin: 0;\">99.7% probability</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(stats_html))\n",
    "\n",
    "print(\"‚úì Statistics display function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Visualization\n",
    "\n",
    "### Controls:\n",
    "- **Number of Molecules**: Adjust from 10¬≤ to 10¬≤¬≥ (1 mole)\n",
    "- **Visualization Mode**: Choose between smooth curve, discrete bars, or both with entropy\n",
    "\n",
    "**Run the cell below to launch the interactive demo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_visualization(log_N, visual_mode):\n",
    "    \"\"\"\n",
    "    Main function to update visualization based on controls.\n",
    "    \"\"\"\n",
    "    # Map dropdown values to internal mode names\n",
    "    mode_map = {\n",
    "        'Smooth (Normal PDF)': 'smooth',\n",
    "        'Discrete (Binomial PMF)': 'discrete',\n",
    "        'Both (with Entropy)': 'both'\n",
    "    }\n",
    "    mode = mode_map[visual_mode]\n",
    "    \n",
    "    # Generate data\n",
    "    data = generate_distribution_data(log_N, mode)\n",
    "    \n",
    "    # Display info banner\n",
    "    N = data['N']\n",
    "    info_text = f\"### Configuration: N = 10^{log_N} = {N:.2e} molecules\"\n",
    "    \n",
    "    if N <= 100_000:\n",
    "        if N <= 1_000_000:\n",
    "            info_text += \" | ‚úì Exact binomial available\"\n",
    "        else:\n",
    "            info_text += \" | Using normal approximation\"\n",
    "    else:\n",
    "        info_text += \" | N too large, using smooth normal\"\n",
    "    \n",
    "    display(Markdown(info_text))\n",
    "    \n",
    "    # Create and display plot\n",
    "    fig = create_distribution_plot(data, mode)\n",
    "    display(fig)\n",
    "    \n",
    "    # Display statistics\n",
    "    display_statistics(data)\n",
    "    \n",
    "    # Display insights\n",
    "    insights = f\"\"\"\n",
    "    ### üîç Key Insights:\n",
    "    \n",
    "    - **Distribution Type**: {'Exact Binomial PMF (computed for N=' + f'{N:.0e}' + ')' if data['is_exact'] \n",
    "                              else 'Normal approximation (discrete bars)' if data['is_discrete'] \n",
    "                              else 'Normal PDF (continuous curve)'}\n",
    "    - **Peak Position**: Exactly at 50% (uniform distribution) - maximum entropy state\n",
    "    - **Width Scaling**: Standard deviation œÉ = ‚àö(N/4), so relative width œÉ/Œº = 1/‚àöN = {data['relative_sd']:.8f}%\n",
    "    - **Macroscopic Limit**: For N = 10¬≤¬≥, width ‚âà 10‚Åª¬π¬≤ %, making uniform distribution the only observable state\n",
    "    \"\"\"\n",
    "    display(Markdown(insights))\n",
    "\n",
    "# Create interactive widgets\n",
    "log_N_slider = widgets.IntSlider(\n",
    "    value=12,\n",
    "    min=2,\n",
    "    max=23,\n",
    "    step=1,\n",
    "    description='log‚ÇÅ‚ÇÄ(N):',\n",
    "    style={'description_width': 'initial'},\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "mode_dropdown = widgets.Dropdown(\n",
    "    options=['Smooth (Normal PDF)', 'Discrete (Binomial PMF)', 'Both (with Entropy)'],\n",
    "    value='Smooth (Normal PDF)',\n",
    "    description='Mode:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create interactive output\n",
    "interactive_plot = widgets.interactive_output(\n",
    "    update_visualization,\n",
    "    {'log_N': log_N_slider, 'visual_mode': mode_dropdown}\n",
    ")\n",
    "\n",
    "# Display controls\n",
    "controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Interactive Controls</h3>\"),\n",
    "    log_N_slider,\n",
    "    mode_dropdown\n",
    "])\n",
    "\n",
    "display(controls)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Mathematical Background\n",
    "\n",
    "### Exact vs. Approximation\n",
    "\n",
    "#### Exact Binomial Distribution (Discrete)\n",
    "\n",
    "For N molecules, each independently choosing left (L) or right (R) with probability p = 0.5:\n",
    "\n",
    "$$P(k) = \\binom{N}{k} \\left(\\frac{1}{2}\\right)^N$$\n",
    "\n",
    "This is the **exact** probability mass function (PMF). For computational efficiency with large N, we use logarithmic methods:\n",
    "\n",
    "$$\\log P(k) = \\log\\binom{N}{k} - N \\log 2$$\n",
    "\n",
    "#### Normal Approximation (Central Limit Theorem)\n",
    "\n",
    "For large N, the binomial distribution converges to a normal distribution:\n",
    "\n",
    "$$P(k) \\approx \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(k-\\mu)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "where:\n",
    "- $\\mu = Np = N/2$ (mean)\n",
    "- $\\sigma = \\sqrt{Np(1-p)} = \\sqrt{N/4}$ (standard deviation)\n",
    "\n",
    "### Key Result: Relative Width Scaling\n",
    "\n",
    "The relative standard deviation (coefficient of variation):\n",
    "\n",
    "$$\\frac{\\sigma}{\\mu} = \\frac{\\sqrt{N/4}}{N/2} = \\frac{1}{\\sqrt{N}}$$\n",
    "\n",
    "This **1/‚àöN scaling** is crucial:\n",
    "- For N = 10¬≤: relative width ‚âà 10%\n",
    "- For N = 10‚Å∂: relative width ‚âà 0.1%\n",
    "- For N = 10¬≤¬≥: relative width ‚âà 10‚Åª¬π¬≤ %\n",
    "\n",
    "### Entropy Connection\n",
    "\n",
    "The thermodynamic entropy for a macrostate with fraction p in the left half:\n",
    "\n",
    "$$S = -k_B N \\left[p \\ln p + (1-p) \\ln(1-p)\\right]$$\n",
    "\n",
    "This reaches its maximum at p = 0.5 (uniform distribution), which is exactly where the probability distribution peaks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exploration Exercises\n",
    "\n",
    "Try these experiments with the interactive visualization above:\n",
    "\n",
    "### Exercise 1: Small System Behavior\n",
    "Set N = 10¬≤ and use **Discrete mode**:\n",
    "- Observe the noticeable spread in the distribution\n",
    "- Notice that deviations from 50% are quite probable\n",
    "- Count how many distinct states are visible\n",
    "\n",
    "### Exercise 2: Convergence to CLT\n",
    "Gradually increase N from 10¬≤ ‚Üí 10‚Å¥ ‚Üí 10‚Å∂:\n",
    "- Watch how the discrete bars merge into a smooth curve\n",
    "- Observe the relative width shrinking\n",
    "- Compare exact binomial vs. normal approximation\n",
    "\n",
    "### Exercise 3: Macroscopic Limit\n",
    "Set N = 10¬≤¬≥ (one mole):\n",
    "- Note the incredibly narrow distribution (width ~ 10‚Åª¬π¬≤ %)\n",
    "- This explains why we never observe significant deviations from equilibrium\n",
    "- The \"deterministic\" behavior of thermodynamics emerges from statistics\n",
    "\n",
    "### Exercise 4: Entropy Analysis\n",
    "Use **Both mode** to see entropy alongside probability:\n",
    "- Maximum entropy occurs at exactly 50% (uniform distribution)\n",
    "- This coincides with the probability peak\n",
    "- Entropy drops rapidly for non-uniform distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Technical Implementation Notes\n",
    "\n",
    "### Computational Considerations\n",
    "\n",
    "1. **Threshold Selection**:\n",
    "   - N ‚â§ 10‚Å∂: Can compute exact binomial PMF using log-space arithmetic\n",
    "   - N > 10‚Å∂: Must use normal approximation to avoid numerical overflow\n",
    "   - Discrete visualization practical only for N ‚â§ 10‚Åµ\n",
    "\n",
    "2. **Logarithmic Methods**:\n",
    "   - Direct computation of C(N,k) causes overflow for large N\n",
    "   - Using log(C(N,k)) = log(N!) - log(k!) - log((N-k)!) avoids overflow\n",
    "   - Stirling's approximation for log(n!) ‚âà n log(n) - n + 0.5 log(2œÄn)\n",
    "\n",
    "3. **Sampling Strategy**:\n",
    "   - Discrete mode: Sample integer k values (computationally intensive)\n",
    "   - Smooth mode: Sample 300 points uniformly in the ¬±6œÉ range\n",
    "   - Focus on ¬±6œÉ region (captures >99.9999% of probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Conclusions\n",
    "\n",
    "### What This Demo Shows\n",
    "\n",
    "1. **Microscopic Randomness**: Each molecule independently chooses left or right\n",
    "2. **Macroscopic Determinism**: For large N, only the uniform distribution is observable\n",
    "3. **CLT Connection**: The 1/‚àöN scaling explains the emergence of thermodynamic behavior\n",
    "4. **Entropy Maximum**: The most probable state (50/50) is also the maximum entropy state\n",
    "\n",
    "### Pedagogical Value\n",
    "\n",
    "This demonstration bridges familiar probability concepts (CLT, binomial distribution) with thermodynamic principles:\n",
    "- **No quantum mechanics needed**: Uses only undergraduate probability\n",
    "- **Exact calculations possible**: Can verify CLT convergence numerically\n",
    "- **Intuitive scaling**: The 1/‚àöN law is easy to understand and calculate\n",
    "- **Direct connection**: Links probability distributions to entropy\n",
    "\n",
    "### Extensions\n",
    "\n",
    "This framework can be extended to:\n",
    "- Multi-compartment systems (multinomial distributions)\n",
    "- Energy distributions (exponential/Boltzmann factors)\n",
    "- Phase space volumes in statistical mechanics\n",
    "- Fluctuation-dissipation theorems\n",
    "\n",
    "---\n",
    "\n",
    "## Citation\n",
    "\n",
    "This notebook accompanies the research paper:\n",
    "\n",
    "**\"Understanding Thermodynamic Entropy Through the Central Limit Theorem: A Pedagogical Approach\"**\n",
    "\n",
    "*Submitted for publication, 2025*\n",
    "\n",
    "---\n",
    "\n",
    "### About\n",
    "\n",
    "**Author**: [Moksh Jayanth]  \n",
    "**Institution**: BMS College of Engineering, Bengaluru  \n",
    "**Contact**: [mokshjayanth@gmail.com]  \n",
    "**Repository**: [https://github.com/mokshjayanth]\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created: November 2025*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
